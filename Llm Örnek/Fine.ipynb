{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zhd0vRBsIis_"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q datasets\n",
        "!pip install -q huggingface-hub\n",
        "!pip install -q safetensors"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hugging Face'e giriş"
      ],
      "metadata": {
        "id": "Bf6x6M0QoILG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login"
      ],
      "metadata": {
        "id": "Uk5oJkSNUqxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "dXtN5Y0lV28-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model ve tokenizer'ı yükleme"
      ],
      "metadata": {
        "id": "qwDb0X85oM_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"google/flan-t5-small\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "Bh_tWoueWrz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Veri Setinin Hazırlanması"
      ],
      "metadata": {
        "id": "1Ubad6KdoXAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python_explain_data = [\n",
        "    {\n",
        "        \"code\": \"\"\"def add(a, b):\n",
        "          return a + b\"\"\",\n",
        "        \"explanation\": \"Bu fonksiyon iki parametre alır (a ve b) ve ikisini toplayarak sonucu döndürür.\"\n",
        "    },\n",
        "    {\n",
        "        \"code\": \"\"\"numbers = [1, 2, 3, 4, 5]\n",
        "          total = 0\n",
        "          for n in numbers:\n",
        "           total += n\n",
        "          print(total)\"\"\",\n",
        "        \"explanation\": \"Önce 1'den 5'e kadar sayılardan oluşan bir liste tanımlanıyor. 'total' değişkeni 0 olarak başlatılıyor. for döngüsüyle listedeki her sayı 'total' üzerine ekleniyor. Son olarak toplam ekrana yazdırılıyor.\"\n",
        "    },\n",
        "    {\n",
        "        \"code\": \"\"\"for i in range(5):\n",
        "          print(\"Hello\", i)\"\"\",\n",
        "        \"explanation\": \"range(5) ifadesi 0'dan 4'e kadar sayılar üretir. Döngü her adımda 'Hello' ve o anki 'i' değerini ekrana yazdırır.\"\n",
        "    },\n",
        "    {\n",
        "        \"code\": \"\"\"def is_even(n):\n",
        "          if n % 2 == 0:\n",
        "            return True\n",
        "          else:\n",
        "            return False\"\"\",\n",
        "        \"explanation\": \"Bu fonksiyon n sayısının 2 ile bölümünden kalanı kontrol eder. Kalan 0 ise sayı çifttir ve True döndürülür, değilse False döndürülür.\"\n",
        "    },\n",
        "    {\n",
        "        \"code\": \"\"\"try:\n",
        "          x = int(input(\"Sayı gir: \"))\n",
        "          print(10 / x)\n",
        "          except ZeroDivisionError:\n",
        "          print(\"Sıfıra bölemezsin!\")\n",
        "\"\"\",\n",
        "        \"explanation\": \"Kullanıcıdan bir sayı alınıp tamsayıya çevrilir. Ardından 10/x hesaplanır. Eğer kullanıcı 0 girerse ZeroDivisionError hatası oluşur ve except bloğu çalışarak uyarı mesajı yazdırılır.\"\n",
        "    },\n",
        "]\n"
      ],
      "metadata": {
        "id": "c8fIizcSbicX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##HuggingFace Dataset nesnesi oluşturma"
      ],
      "metadata": {
        "id": "giJEpP0hosT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "def make_example(example):\n",
        "    instruction = (\n",
        "        \"Türkçe ve anlaşılır bir şekilde, aşağıdaki Python kodunu satır satır açıkla:\\n\"\n",
        "        f\"{example['code']}\"\n",
        "    )\n",
        "    target = example[\"explanation\"]\n",
        "    return {\"input_text\": instruction, \"target_text\": target}\n",
        "\n",
        "converted = [make_example(e) for e in python_explain_data] #Listedeki her elemanı birer örneğe dönüştürüyoruz\n",
        "dataset = Dataset.from_list(converted) #Listeyi HuggingFace dataset formatında dönüştürüyoruz\n",
        "dataset = dataset.train_test_split(test_size=0.2, seed=42) #Veri setini dağıtıyoruz train %80 test %20"
      ],
      "metadata": {
        "id": "j_bbaBGcbokO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "3ZhnNHyLpcz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "id": "f7Pr7BK6pes9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenization ayarları"
      ],
      "metadata": {
        "id": "Ht7hriRqpjgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length =  #girdi\n",
        "max_target_length = 128 #çıktı\n",
        "\n",
        "def preprocess(batch):\n",
        "    # Encoder\n",
        "    model_inputs = tokenizer(\n",
        "        batch[\"input_text\"],\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,        # max_input_length'i aşarsa kes\n",
        "        padding=\"max_length\",   # max_input_length'e kadar padding yap\n",
        "    )\n",
        "\n",
        "    # Decoder\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            batch[\"target_text\"],\n",
        "            max_length=max_target_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "        )\n",
        "\n",
        "    #doğru cevaplar temsil ediliyor\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "P85wZPfAbuC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess fonktiyonları uygulanır ve input/target kolonları kaldırılır"
      ],
      "metadata": {
        "id": "DYn43K1TqLK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(preprocess, batched=True, remove_columns=[\"input_text\", \"target_text\"])"
      ],
      "metadata": {
        "id": "3_lToT_ZqGTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "Z6enCj_9qIMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data collator ve eğitim argümanları"
      ],
      "metadata": {
        "id": "m86vonatqjif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"evaluate\" ekleyip metrik karşılaşması yapılabilir"
      ],
      "metadata": {
        "id": "A-b6pVtzci4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model) #dinamik padding ile model beslenir\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"flan-t5-python-explainer\",\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=20,\n",
        "    logging_steps=10,\n",
        "    save_steps=50,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=100,             #Toplam epoch sayısı\n",
        "    learning_rate=5e-5,               #Öğrenme oranı\n",
        "    predict_with_generate=True,\n",
        "    fp16=False,\n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=False,\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,                                # Eğitilecek model\n",
        "    args=training_args,                         # Eğitim ayarları\n",
        "    train_dataset=tokenized_dataset[\"train\"],   # Eğitim verisi\n",
        "    eval_dataset=tokenized_dataset[\"test\"],     # Test verisi\n",
        "    tokenizer=tokenizer,                        # Tokenizer\n",
        "    data_collator=data_collator,\n",
        ")\n"
      ],
      "metadata": {
        "id": "jKs_OrQlbzo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "trant9b6cxqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeli kaydetme"
      ],
      "metadata": {
        "id": "zRwxTcg9rPiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"flan-t5-python-explainer\")\n",
        "tokenizer.save_pretrained(\"flan-t5-python-explainer\")"
      ],
      "metadata": {
        "id": "Poih_tpcdCAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Yeni kodları açıklayan fonksiyon tanımlama"
      ],
      "metadata": {
        "id": "py1EEAZJrXMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu fonksiyon, verilen Python kodu için Türkçe açıklama üretir."
      ],
      "metadata": {
        "id": "yr0FkCxmrcOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def explain_code(code: str, max_new_tokens: int = 128) -> str:\n",
        "    instruction = (\n",
        "        \"Türkçe ve anlaşılır bir şekilde, aşağıdaki Python kodunu satır satır açıkla:\\n\"\n",
        "        f\"{code}\"\n",
        "    )\n",
        "\n",
        "    # Instructionı token'lara çeviriyoruz.\n",
        "    inputs = tokenizer(\n",
        "        instruction,\n",
        "        return_tensors=\"pt\",          # PyTorch tensör formatında döndür\n",
        "        truncation=True,\n",
        "        max_length=max_input_length,\n",
        "    ).to(model.device)                # Modelin çalıştığı cihaza (CPU/GPU) gönder\n",
        "\n",
        "    #Modelin çıktısı\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        num_beams=4,\n",
        "        early_stopping=True,          # Uygunsa modeli durdur\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()"
      ],
      "metadata": {
        "id": "oZKuJ9KPdKXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test"
      ],
      "metadata": {
        "id": "x_z1bMyprzrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_code = \"\"\"my_list = [10, 20, 30]\n",
        "for i, val in enumerate(my_list):\n",
        "    print(i, val)\"\"\"\n",
        "\n",
        "print(explain_code(test_code))"
      ],
      "metadata": {
        "id": "zBZUqiicdRLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##HuggingFace"
      ],
      "metadata": {
        "id": "e3TiNcerhEQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r flan-t5-python-explainer.zip flan-t5-python-explainer"
      ],
      "metadata": {
        "id": "l2E5G3Lijyl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"flan-t5-python-explainer.zip\")"
      ],
      "metadata": {
        "id": "HWjZBAKJj2Xx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}