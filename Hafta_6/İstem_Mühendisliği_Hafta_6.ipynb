{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch -Uq\n",
        "!pip install transformers -Uq\n",
        "!pip install tiktoken -Uq\n",
        "!pip install datasets -Uq\n",
        "!pip install matplotlib -Uq"
      ],
      "metadata": {
        "id": "TMtz7Fpb0X_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxiEf_LTw-JO"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import plotly.graph_objects as go\n",
        "import plotly.offline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "  def __init__(self, vocab_path):\n",
        "    with open(vocab_path, \"r\", encoding=\"utf-8\") as f:\n",
        "      self.vocab = json.load(f)\n",
        "      self.reverse_vocab = {v: k for k, v in self.vocab.items()}\n",
        "\n",
        "  def encode(self, text):\n",
        "    tokens = []\n",
        "\n",
        "    for word in text.split():\n",
        "      i = 0\n",
        "      while i < len(word):\n",
        "        found_match = False\n",
        "        for j in range(len(word), i, -1):\n",
        "          subword = word[i:j]\n",
        "          if subword in self.vocab:\n",
        "            tokens.append(self.vocab[subword])\n",
        "            i = j\n",
        "            found_match = True\n",
        "            break\n",
        "        if not found_match:\n",
        "          tokens.append(self.vocab.get(\"<unk>\", 0))\n",
        "          i += 1\n",
        "      tokens.append(self.vocab.get(\" \", 1))\n",
        "    if tokens:\n",
        "      tokens.pop()\n",
        "    return tokens\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    token_ids = self.encode(text)\n",
        "    return [self.reverse_vocab[id] for id in token_ids]\n",
        "\n",
        "  def decode(self, ids):\n",
        "    text = \"\"\n",
        "    for id in ids:\n",
        "      text += self.reverse_vocab.get(id, \"<unk>\")\n",
        "    return text"
      ],
      "metadata": {
        "id": "yjOk0RFLxXgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rotary_position_encoding(input: torch.Tensor, base=10000, device=\"cpu\"):\n",
        "  context_length, dimension = input.shape\n",
        "\n",
        "  assert dimension % 2 == 0, \"boyutlar eşit olmalıdır\"\n",
        "\n",
        "  half_dimension = dimension // 2\n",
        "\n",
        "  freqs_indices = torch.arange(0, half_dimension, device=device, dtype=torch.float32)\n",
        "  freqs = 1.0 / (base ** (freqs_indices / dimension))\n",
        "\n",
        "  positions = torch.arange(0, context_length, device=device, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "  angles = positions * freqs\n",
        "\n",
        "  sin_angles = torch.sin(angles)\n",
        "  cos_angles = torch.cos(angles)\n",
        "\n",
        "  input_even = input[:, :dimension // 2]\n",
        "  input_odd = input[:, dimension // 2:]\n",
        "\n",
        "  input_even_rotated = input_even * cos_angles - input_odd * sin_angles\n",
        "  input_odd_rotated = input_even * sin_angles + input_odd * cos_angles\n",
        "\n",
        "  input_rotated = torch.empty_like(input)\n",
        "\n",
        "  input_rotated[:, :dimension // 2] = input_even_rotated\n",
        "  input_rotated[:, dimension // 2:] = input_odd_rotated\n",
        "\n",
        "  return input_rotated"
      ],
      "metadata": {
        "id": "M696kvFbyqXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UstaModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, context_length):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    self.get_pos = get_rotary_position_encoding\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    x = self.get_pos(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "mSeqspJMxhfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_dots(sentences_data, title, dims=[0, 1, 2]):\n",
        "  data = [\n",
        "    go.Scatter3d(\n",
        "      x=sentence_data[\"words\"][:, dims[0]],\n",
        "      y=sentence_data[\"words\"][:, dims[1]],\n",
        "      z=sentence_data[\"words\"][:, dims[2]],\n",
        "      mode=\"markers+text\",\n",
        "      marker=dict(\n",
        "        size=6,\n",
        "        color=sentence_data[\"color\"],\n",
        "      ),\n",
        "      text=sentence_data[\"labels\"],\n",
        "      hoverinfo=\"text\",\n",
        "    ) for sentence_data in sentences_data\n",
        "  ]\n",
        "\n",
        "  layout = go.Layout(\n",
        "    scene=dict(\n",
        "      xaxis_title=\"Hardness\",\n",
        "      yaxis_title=\"Brightness\",\n",
        "      zaxis_title=\"Redness\",\n",
        "    ),\n",
        "    title=title,\n",
        "    width=1000,\n",
        "    height=1000,\n",
        "  )\n",
        "\n",
        "  fig = go.Figure(data=data, layout=layout)\n",
        "  plotly.offline.iplot(fig)"
      ],
      "metadata": {
        "id": "FdD84jrxVHbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tekrar Edelim"
      ],
      "metadata": {
        "id": "K0o4YlMXXEbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(\"tokenizer_1.json\")"
      ],
      "metadata": {
        "id": "VWJm0qvQXFpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"the capital of united states and the capital of france\""
      ],
      "metadata": {
        "id": "kLcr6FArXG4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.encode(prompt)"
      ],
      "metadata": {
        "id": "IPGzH0s5XIdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(tokens, dtype=torch.long)"
      ],
      "metadata": {
        "id": "NrGmS477XJJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "T7E4gfAwXKwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UstaModel(vocab_size=len(tokenizer.vocab), embedding_dim=4, context_length=32)"
      ],
      "metadata": {
        "id": "cDOLegwgXL2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(x)"
      ],
      "metadata": {
        "id": "Qfwb8tSjXMtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_meanings = model(x)"
      ],
      "metadata": {
        "id": "790J9jNKcuN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_meanings.shape"
      ],
      "metadata": {
        "id": "BblwKGejcvcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "  {\n",
        "    \"words\": sentence_meanings.detach().numpy(),\n",
        "    \"labels\": tokenizer.tokenize(prompt),\n",
        "    \"color\": \"red\",\n",
        "  },\n",
        "]\n",
        "\n",
        "plot_dots(sentences, \"Models Context Space\")"
      ],
      "metadata": {
        "id": "uKBmC_rVcv6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention"
      ],
      "metadata": {
        "id": "mWE4_R-zYAA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Her kelimenin diğer kelimelere ne kadar dikkat etmesi gerektiğini” sayısal olarak hesaplar"
      ],
      "metadata": {
        "id": "Y8wZ9xnNYCB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Manhattan Mesafe Ölçeği"
      ],
      "metadata": {
        "id": "2iW7c4tAW7rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_meanings"
      ],
      "metadata": {
        "id": "HvDspibwXCyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_pos = [1.9269,  1.4873,  0.9007, -2.1055]\n",
        "capital_pos = [-0.2432, -0.8911,  0.6348, -1.8179]"
      ],
      "metadata": {
        "id": "TulDfL95c3av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hardness_dist = the_pos[0] - capital_pos[0]\n",
        "brightness_dist = the_pos[1] - capital_pos[1]\n",
        "redness_dist = the_pos[2] - capital_pos[2]\n",
        "blue_dist = the_pos[3] - capital_pos[3]"
      ],
      "metadata": {
        "id": "yjH5FXLhc9zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hardness_dist, brightness_dist, redness_dist, blue_dist"
      ],
      "metadata": {
        "id": "NUOC1H8ac_pH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_dis = abs(hardness_dist) + abs(brightness_dist) + abs(redness_dist) + abs(blue_dist)"
      ],
      "metadata": {
        "id": "lwqPbsHrdBhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_dis"
      ],
      "metadata": {
        "id": "jCORTceidCov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cosinus Benzerliği Mesafe Ölçümü"
      ],
      "metadata": {
        "id": "OuWimAwndpTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Originden iki kelime arasındaki açının kosinüsünü alıp benzerliğini ölçer"
      ],
      "metadata": {
        "id": "W-xPZ5T5du6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gerçek Manhatten ya da Cosinus benzerliği kullanmak zorunda değiliz"
      ],
      "metadata": {
        "id": "rOkqbbaLd9JQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Önceden belirlediğimiz herhangi bir kurala göre eğitirsek de aynı noktaya varacağız"
      ],
      "metadata": {
        "id": "lFqumJEYeYRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "the_pos = [1.9269,  1.4873,  0.9007, -2.1055]\n",
        "capital_pos = [-0.2432, -0.8911,  0.6348, -1.8179]"
      ],
      "metadata": {
        "id": "38xdVN7qityb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cos_sim_hardness = the_pos[0] * capital_pos[0]\n",
        "cos_sim_brightness = the_pos[1] * capital_pos[1]\n",
        "cos_sim_redness = the_pos[2] * capital_pos[2]\n",
        "cos_sim_blue = the_pos[3] * capital_pos[3]"
      ],
      "metadata": {
        "id": "PBLWWw9rivWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_cos_sim = cos_sim_hardness + cos_sim_brightness + cos_sim_redness + cos_sim_blue"
      ],
      "metadata": {
        "id": "ZtgO7nVAivyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cos_sim_hardness, cos_sim_brightness, cos_sim_redness, cos_sim_blue, total_cos_sim"
      ],
      "metadata": {
        "id": "toXK7lz1iw-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_meanings[0], sentence_meanings[1],  sentence_meanings[2],  sentence_meanings[3]"
      ],
      "metadata": {
        "id": "4-UWfPEAiywa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cs_0_0 = sentence_meanings[0][0] * sentence_meanings[0][0] + sentence_meanings[0][1] * sentence_meanings[0][1] + sentence_meanings[0][2] * sentence_meanings[0][2] + sentence_meanings[0][3] * sentence_meanings[0][3]\n",
        "cs_0_1 = sentence_meanings[0][0] * sentence_meanings[1][0] + sentence_meanings[0][1] * sentence_meanings[1][1] + sentence_meanings[0][2] * sentence_meanings[1][2] + sentence_meanings[0][3] * sentence_meanings[1][3]\n",
        "cs_0_2 = sentence_meanings[0][0] * sentence_meanings[2][0] + sentence_meanings[0][1] * sentence_meanings[2][1] + sentence_meanings[0][2] * sentence_meanings[2][2] + sentence_meanings[0][3] * sentence_meanings[2][3]\n",
        "cs_0_3 = sentence_meanings[0][0] * sentence_meanings[3][0] + sentence_meanings[0][1] * sentence_meanings[3][1] + sentence_meanings[0][2] * sentence_meanings[3][2] + sentence_meanings[0][3] * sentence_meanings[3][3]"
      ],
      "metadata": {
        "id": "MK2ZyrMGi19y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cs_0_0, cs_0_1, cs_0_2, cs_0_3"
      ],
      "metadata": {
        "id": "iVMvptFoi6Sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_similarities = []\n",
        "\n",
        "for i in range(sentence_meanings.shape[0]):\n",
        "  cs_the_i = sentence_meanings[0][0] * sentence_meanings[i][0] + sentence_meanings[0][1] * sentence_meanings[i][1] + sentence_meanings[0][2] * sentence_meanings[i][2] + sentence_meanings[0][3] * sentence_meanings[i][3]\n",
        "  the_similarities.append(cs_the_i)"
      ],
      "metadata": {
        "id": "O1ELx0K9i9ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_similarities"
      ],
      "metadata": {
        "id": "Nr_jvLDci-AI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torch üzerinde işlem yapmadan önce boş yerlerini oluşturmamız gerekir"
      ],
      "metadata": {
        "id": "R-26F0GZjHv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_similarities = torch.zeros(sentence_meanings.shape[0], sentence_meanings.shape[0])\n",
        "for j in range(sentence_meanings.shape[0]):\n",
        "  j_similarities = torch.zeros(sentence_meanings.shape[0])\n",
        "\n",
        "  for i in range(sentence_meanings.shape[0]):\n",
        "    for k in range(sentence_meanings.shape[1]):\n",
        "      cs_j_i = sentence_meanings[j][k] * sentence_meanings[i][k]\n",
        "      j_similarities[i] += cs_j_i\n",
        "\n",
        "  all_similarities[j] = j_similarities"
      ],
      "metadata": {
        "id": "xMktbDkNjCJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_similarities.detach().numpy()"
      ],
      "metadata": {
        "id": "U-NPZdIqjOoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_similarities.shape"
      ],
      "metadata": {
        "id": "fgAJOkAwjYCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_meanings.shape, sentence_meanings.T.shape"
      ],
      "metadata": {
        "id": "KQZikJ7OjQs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_sim_torch = sentence_meanings @ sentence_meanings.T"
      ],
      "metadata": {
        "id": "L-D2fV2VjRgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_sim_torch.shape"
      ],
      "metadata": {
        "id": "NH_Gn3IUjTfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_sim_torch"
      ],
      "metadata": {
        "id": "v8dsSx7vjVRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doğasını bozmadan daha yönetilebilir bir hale getirilmesi normalizasyon sayesinde gerçekleşir"
      ],
      "metadata": {
        "id": "9oyVGohyxMna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# attention_weights = all_similarities / all_similarities.sum(dim=1, keepdim=True)"
      ],
      "metadata": {
        "id": "JLPWK9sCxWjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = torch.softmax(all_similarities, dim=1)"
      ],
      "metadata": {
        "id": "drONIpoGxXvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights"
      ],
      "metadata": {
        "id": "vI_xwfjSxZJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(all_sim_torch[0]), torch.sum(attention_weights[0])"
      ],
      "metadata": {
        "id": "EOX6AijtxbdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_context_vector = attention_weights @ sentence_meanings"
      ],
      "metadata": {
        "id": "dw7rD_oAxefL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_context_vector"
      ],
      "metadata": {
        "id": "VvTgYUnOxfqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_meanings"
      ],
      "metadata": {
        "id": "kxg4y-6oxlBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_meaning_without_pos = model.embedding(x)"
      ],
      "metadata": {
        "id": "6_hKL87DxnlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Simple Self Attention"
      ],
      "metadata": {
        "id": "eLhQmojOxppC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "  {\n",
        "    \"words\": sentence_meanings.detach().numpy(),\n",
        "    \"labels\": tokenizer.tokenize(prompt),\n",
        "    \"color\": \"purple\",\n",
        "  },\n",
        "  {\n",
        "    \"words\": sentence_context_vector.detach().numpy(),\n",
        "    \"labels\": tokenizer.tokenize(prompt),\n",
        "    \"color\": \"orange\",\n",
        "  },\n",
        "  {\n",
        "    \"words\": sentence_meaning_without_pos.detach().numpy(),\n",
        "    \"labels\": tokenizer.tokenize(prompt),\n",
        "    \"color\": \"blue\",\n",
        "  },\n",
        "]\n",
        "\n",
        "plot_dots(sentences, \"Models Attention Sentence Space\")"
      ],
      "metadata": {
        "id": "jexxJmVyxrT5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}